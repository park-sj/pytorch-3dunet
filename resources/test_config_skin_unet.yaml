model_path: 3dunet/220117_revunet_GrAc_skin_iter7000.pytorch
# model configuration
model:
  # model class, e.g. UNet3D, ResidualUNet3D, NoNewReversible
  name: NoNewReversible
  # number of input channels to the model
  in_channels: 1
  # number of output channels
  out_channels: 1
  # determines the order of operators in a single layer (gcr - GroupNorm+Conv3d+ReLU)
  layer_order: gcr
  # feature maps scale factor
  f_maps: 4
  # number of channels in each layer (num_levels를 넘는 index의 element는 무시될 것임) 
  channels: [16, 32, 64, 128, 256]
  # number of groups in the groupnorm
  num_groups: 4
  # number of levels in the encoder/decoder path
  num_levels: 4
  # apply element-wise nn.Sigmoid after the final 1x1 convolution, otherwise apply nn.Softmax
  final_sigmoid: true
  # if True applies the final normalization layer (sigmoid or softmax), otherwise the networks returns the output from the final convolution layer; use False for regression problems, e.g. de-noising
  is_segmentation: true
# predictor configuration
predictor:
  name: 'StandardPredictor'
  # Thresholding output to make it 0, 1 binary
  transformer:
    raw:
      - name: Thresholding
        threshold: 0.5
# specify the test datasets
loaders:
  # when reading from multiple threads.
  dataset: DicomDataset
  # batch dimension; if number of GPUs is N > 1, then a batch_size of N * batch_size will automatically be taken for DataParallel
  batch_size: 1
  # how many subprocesses to use for data loading
  num_workers: 4
  # path to the raw data within the H5
  raw_internal_path: raw
  # path to the the label data withtin the H5
  label_internal_path: label
  # path to the pixel-wise weight map withing the H5 if present
  weight_internal_path: null
  # configuration of the test loader
  test:
    # paths to the files to predict
    file_paths:
      - 'io/test'
    # The path where the result is saved to
    save_paths: 
      - 'io/save'
    slice_builder:
      # SliceBuilder class
      name: SliceBuilder
      # train patch size given to the network (adapt to fit in your GPU mem, generally the bigger patch the better)
      patch_shape: [296, 296, 296]
      stride_shape: [120, 120, 120] # [120, 96] or [240, 180]
    transformer:
      raw:
        # crop some axial slices for robust training
        - name: AxialCrop
          lower_end: 100
          upper_end: -100
          # execute only when the number of slices exceeds the criterion
          criterion: 600
        # min-max scaling, range of the data shrinks to [-1,1]
        - name: Normalize
          min_value: -750
          max_value: 1250
        # resize by scikit-image library
        - name: Resize
          shape: [296, 296, 296]
        # convert to torch tensor
        - name: ToTensor
          # add additional 'channel' axis when the input data is 3D
          expand_dims: true
      label:
        # crop some axial slices for robust training
        - name: AxialCrop
          lower_end: 100
          upper_end: -100
        # resize by scikit-image library
        - name: Resize
          shape: [296, 296, 296]
        - name: ToTensor
          expand_dims: true
